///////////////////////////////////////////////////////////////////////////////

    Copyright (c) 2021, Oracle and/or its affiliates.
    Licensed under the Universal Permissive License v 1.0 as shown at
    http://oss.oracle.com/licenses/upl.

///////////////////////////////////////////////////////////////////////////////
== Secure Coherence with TLS

This example is going to show how to use TLS (or SSL) to secure communication between different parts of a Coherence cluster and applications. This is quite a long guide as there are a number of things that can be secured wth TLS.

This example shows how to secure various parts of Coherence clusters using TLS.
You can find the source code in the https://github.com/oracle/coherence-operator/tree/master/examples/tls[Operator GitHub Repo]

In this example we are going to use https://cert-manager.io[Cert Manager] to manage the keys and certs for our Coherence server and clients. Cert Manage makes managing certificates in Kubernetes very simple, but it isn't the only solution.

Although securing clusters with TLS is a common request, if running in a secure isolated Kubernetes cluster, you need to weigh up the pros and cons regarding the performance impact TLS will give over the additional security.

Using Cert Manager we will ultimately end up with four k8s `Secrets`:

* A `Secret` containing the server keys, certs, keystore and truststore
* A `Secret` containing a single file containing the server keystore, truststore and key password
* A `Secret` containing the client keys, certs, keystore and truststore
* A `Secret` containing a single file containing the client keystore, truststore and key password

If you do not want to use Cert Manager to try this example then a long as you have a way to create the required `Secrets` containing the keys and passwords above then you can skip to the section on <<coherence,Securing Coherence>>.

=== What the Example will Cover

* <<install_operator,Install the Operator>>
* <<setup_cert_manager,Setting Up Cert-Manager>>
** <<create_self_signed_issuer,Create the SelfSigned Issuer>>
** <<create_ce_cert,Create the CA Certificate>>
** <<create_ca_issuer,Create the CA issuer>>
** <<create_coherence_keystores,Create the Coherence Keys, Certs and KeyStores>>
*** <<server_password_secret,Create the Server Keystore Password Secret>>
*** <<server_cert,Create the Server Certificate>>
*** <<client_certs,Create the Client Certificate>>
* <<coherence,Securing Coherence Clusters>>
** <<images,Build the Example Images>>
** <<socket_provider,Configure a Socket Provider>>
* <<tcmp,Secure Cluster Membership>>
* <<extend,Secure Extend>>
* <<grpc,Secure gRPC>>


[#install_operator]
=== Install the Operator

To run the examples below, you will need to have installed the Coherence Operator, do this using whatever method you prefer from the https://oracle.github.io/coherence-operator/docs/latest/#/installation/01_installation[Installation Guide]

[#setup_cert_manager]
=== Setting Up Cert-Manager

In this example we will use self-signed certs as this makes everything easy to get going.
Cert Manager has a number of ways to configure real certificates for production use.
Assuming that you've installed Cert Manager using one of the methods in its https://cert-manager.io/docs/installation/[Install Guide] we can proceed to created all of the required resources.

[#create_self_signed_issuer]
==== Create the SelfSigned Issuer

This is used to generate a root CA for use with the CA Issuer.
Here we are using a `ClusterIssuer` so that we can use a single self-signed issuer across all namespaces.
We could have instead created an `Issuer` in a single namespace.

[source,yaml]
.manifests/selfsigned-issuer.yaml
----
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: selfsigned-issuer
spec:
  selfSigned: {}
----

Create the `ClusterIssuer` with the following command. As this is a `ClusterIssuer`, is does not require a namespace.
[source,bash]
----
kubectl apply -f manifests/selfsigned-issuer.yaml
----

We can list the `ClusterIssuers` in the cluster:
[source,bash]
----
kubectl get clusterissuer
----
We should see that the `selfsigned-issuer` is present and is ready.
[source,bash]
----
NAME                READY   AGE
selfsigned-issuer   True    14m
----

[#create_ce_cert]
=== Create the CA Certificate

Weâ€™re going to create an internal CA that will be used to sign our certificate requests for the Coherence server and clients that we will run later. Both the server and client will use the CA to validate a connection.

To create the CA issuer, first create a self-signed CA certificate.

[source,yaml]
.manifests/ca-cert.yaml
----
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: ca-certificate
spec:
  issuerRef:
    name: selfsigned-issuer   # <1>
    kind: ClusterIssuer
    group: cert-manager.io
  secretName: ca-cert        # <2>
  duration: 2880h # 120d
  renewBefore: 360h # 15d
  commonName: Cert Admin
  isCA: true                 # <3>
  privateKey:
    size: 2048
  usages:
    - digital signature
    - key encipherment
----
<1> The certificate will use the `selfsigned-issuer` cluster issuer we created above.
<2> There will be a secret named `ca-cert` created containing the key and certificate
<3> Note that the `isCA` field is set to `true` in the body of the spec.

The CA issuer that we will create later will also be a `ClusterIssuer`, so in order for the issuer to find the `Certificate` above we will create the certificate in the `cert-manager` namespace, which is where Cert Manager is running.

[source,bash]
----
kubectl -n cert-manager apply -f manifests/ca-cert.yaml
----

We can see that the certificate was created and should be ready:
[source,bash]
----
kubectl -n cert-manager get certificate
----

[source,bash]
----
NAME             READY   SECRET    AGE
ca-certificate   True    ca-cert   12m
----

There will also be a secret named `ca-secret` created in the `cert-manager` namespace.
The Secret will contain the certificate and signing key, this will be created when the CA certificate is deployed, and the CA issuer will reference that secret.

[#create_ca_issuer]
=== Create the CA issuer.

As with the self-signed issuer above, we will create a `ClusterIssuer` for the CA issuer.

[source,bash]
.manifests/ca-cert.yaml
----
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: ca-issuer
spec:
  ca:
    secretName: ca-cert  # <1>
----
<1> The `ca-issuer` will use the `ca-cert` secret created by the `ca-certificate` `Certificate` we created above.

Create the CA issuer with the following command. As this is a `ClusterIssuer`, is does not require a namespace.

[source,bash]
----
kubectl apply -f manifests/ca-issuer.yaml
----

You can then check that the issuer have been successfully configured by checking the status.
[source,bash]
----
kubectl get clusterissuer
----
We should see that both `ClusterIssuers` we created are present and is ready.
[source,bash]
----
NAME                READY   AGE
ca-issuer           True    22m
selfsigned-issuer   True    31m
----

[#create_coherence_keystores]
=== Create the Coherence Keys, Certs and KeyStores

As the Coherence server, and client in this example, are Java applications they will require Java keystores to hold the certificates. We can use Cert-Manager to create these for us.

==== Create a Namespace

We will run the Coherence cluster in a namespace called `coherence-test`, so we will first create this:
[source,bash]
----
kubectl create ns coherence-test
----

[#server_password_secret]
==== Create the Server Keystore Password Secret

The keystore will be secured with a password. We will create this password in a `Secret` so that Cert-Manager can find and use it.
The simplest way to create this secret is with kubectl:

[source,bash]
----
kubectl -n coherence-test create secret generic \
    server-keystore-secret --from-literal=password-key=[your-password]
----

...replacing `[your-password]` with the actual password you want to use.
Resulting in a `Secret` similar to this:

[source,bash]
.manifests/ca-cert.yaml
----
apiVersion: v1
kind: Secret
metadata:
  name: server-keystore-secret
data:
  password-key: "cGFzc3dvcmQ=" # <1>
----
<1> In this example the password used is `password`

[#server_cert]
==== Create the Server Certificate

We can now create the server certificate and keystore.

[source,yaml]
.manifests/server-keystore.yaml
----
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: server-keystore
spec:
  issuerRef:
    name: ca-issuer                   # <1>
    kind: ClusterIssuer
    group: cert-manager.io
  secretName: coherence-server-certs  # <2>
  keystores:
    jks:
      create: true
      passwordSecretRef:
        key: password-key
        name: server-keystore-secret  # <3>
  duration: 2160h # 90d
  renewBefore: 360h # 15d
  privateKey:
    size: 2048
    algorithm: RSA
    encoding: PKCS1
  usages:
    - digital signature
    - key encipherment
    - client auth
    - server auth
  commonName: Coherence Certs
----

<1> The issuer will the `ClusterIssuer` named `ca-issuer` that we created above.
<2> The keys, certs and keystores will be created in a secret named `coherence-server-certs`
<3> The keystore password secret is the `Secret` named `server-keystore-secret` we created above

We can create the certificate in the `coherence-test` namespace with the following command:

[source,bash]
----
kubectl -n coherence-test apply -f manifests/server-keystore.yaml
----

If we list the certificate in the `coherence-test` namespace we should see the new certificate and that it is ready.

[source,bash]
----
kubectl -n coherence-test get certificate
----

[source,bash]
----
NAME              READY   SECRET                   AGE
server-keystore   True    coherence-server-certs   4s
----

If we list the secrets in the `coherence-test` namespace we should see both the password secret and the keystore secret:

[source,bash]
----
kubectl -n coherence-test get secret
----

[source,bash]
----
NAME                     TYPE                 DATA   AGE
coherence-server-certs   kubernetes.io/tls    5      117s
server-keystore-secret   Opaque               1      2m9s
----

[#client_certs]
==== Create the Client Certificate

We can create the certificates and keystores for the client in exactly the same way we did for the server.

Create a password secret for the client keystore:
[source,bash]
----
kubectl -n coherence-test create secret generic \
    client-keystore-secret --from-literal=password-key=[your-password]
----

Create the client certificate and keystore.

[source,yaml]
.manifests/client-keystore.yaml
----
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: client-keystore
spec:
  issuerRef:
    name: ca-issuer                   # <1>
    kind: ClusterIssuer
    group: cert-manager.io
  secretName: coherence-client-certs  # <2>
  keystores:
    jks:
      create: true
      passwordSecretRef:
        key: password-key
        name: client-keystore-secret  # <3>
  duration: 2160h # 90d
  renewBefore: 360h # 15d
  privateKey:
    size: 2048
    algorithm: RSA
    encoding: PKCS1
  usages:
    - digital signature
    - key encipherment
    - client auth
  commonName: Coherence Certs
----

<1> The issuer is the same cluster-wide `ca-issuer` that we used for the server.
<2> The keys, certs and keystores will be created in a secret named `coherence-client-certs`
<3> The keystore password secret is the `Secret` named `client-keystore-secret` we created above

[source,bash]
----
kubectl -n coherence-test apply -f manifests/client-keystore.yaml
----

If we list the certificate in the `coherence-test` namespace we should see the new client certificate and that it is ready.

[source,bash]
----
kubectl -n coherence-test get certificate
----

[source]
----
NAME              READY   SECRET                   AGE
client-keystore   True    coherence-client-certs   12s
server-keystore   True    coherence-server-certs   2m13s
----



[#coherence]
== Securing Coherence

By this point, you should have installed the Operator and have the four `Secrets` required, either created by Cert Manager, or manually. Now we can secure Coherence clusters.

[#images]
=== Build the Test Images

This example includes a Maven project that will build a Coherence server and client images with configuration files that allow us to easily demonstrate TLS. To build the images run the following command:

[source,bash]
----
./mvnw clean package jib:dockerBuild
----

This will produce two images:

* `tls-example-server:1.0.0`
* `tls-example-client:1.0.0`

These images can run secure or insecure depending on various system properties passed in at runtime.

[#socket_provider]
=== Configure a Socket Provider

When configuring Coherence to use TLS, we need to configure a socket provider that Coherence can use to create secure socket. We then tell Coherence to use this provider in various places, such as Extend connections, cluster member TCMP connections etc.
This configuration is typically done by adding the provider configuration to the Coherence operational configuration override file.

The Coherence documentation has a lot of details on configuring socket providers in the section on https://docs.oracle.com/en/middleware/standalone/coherence/14.1.1.0/secure/using-ssl-secure-communication.html#GUID-21CBAF48-BA78-4373-AC90-BF668CF31776[Using SSL Secure Communication]

Below is an example that we will use on the server cluster members
[source,xml]
.src/main/resources/tls-coherence-override.xml
----
<coherence xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns="http://xmlns.oracle.com/coherence/coherence-operational-config"
    xsi:schemaLocation="http://xmlns.oracle.com/coherence/coherence-operational-config coherence-operational-config.xsd">
  <cluster-config>
    <socket-providers>
      <socket-provider id="tls">
        <ssl>
          <protocol>TLS</protocol>
          <identity-manager>
            <key-store>
              <url system-property="coherence.tls.keystore"/>
              <password-provider>
                <class-name>com.oracle.coherence.k8s.FileBasedPasswordProvider</class-name>
                  <init-params>
                    <init-param>
                      <param-type>String</param-type>
                      <param-value system-property="coherence.tls.keystore.password">/empty.txt</param-value>
                    </init-param>
                </init-params>
              </password-provider>
            </key-store>
            <password-provider>
              <class-name>com.oracle.coherence.k8s.FileBasedPasswordProvider</class-name>
              <init-params>
                <init-param>
                  <param-type>String</param-type>
                  <param-value system-property="coherence.tls.key.password">/empty.txt</param-value>
              </init-param>
            </init-params>
          </password-provider>
          </identity-manager>
          <trust-manager>
            <key-store>
              <url system-property="coherence.tls.truststore"/>
              <password-provider>
                <class-name>com.oracle.coherence.k8s.FileBasedPasswordProvider</class-name>
                <init-params>
                  <init-param>
                    <param-type>String</param-type>
                    <param-value system-property="coherence.tls.truststore.password">/empty.txt</param-value>
                  </init-param>
                </init-params>
              </password-provider>
            </key-store>
          </trust-manager>
        </ssl>
      </socket-provider>
    </socket-providers>
  </cluster-config>
</coherence>
----

The file above has a number of key parts.

We must give the provider a name so that we can refer to it in other configuration.
This is done by setting the `id` attribute of the `<socket-provider>` element. In this case we name the provider "tls" in `<socket-provider id="tls">`.

We set the `<protocol>` element to TLS to tell Coherence that this is a TLS socket.

We need to set the keystore URL. If we always used a common location, we could hard code it in the configuration. In this case we will configure the `<keystore><url>` element to be injected from a system property which we will configure at runtime `<url system-property="coherence.tls.keystore"/>`.

We obviously do not want hard-coded passwords in our configuration.
In this example we will use a password provider, which is a class implementing the `com.tangosol.net.PasswordProvider` interface, that can provide the password by reading file.
In this case the file will be the one from the password secret created above that we will mount into the container.

[source,xml]
.src/main/resources/server-cache-config.xml
----
<password-provider>
  <class-name>com.oracle.coherence.k8s.FileBasedPasswordProvider</class-name>
    <init-params>
      <init-param>
        <param-type>String</param-type>
        <param-value system-property="coherence.tls.keystore.password"/>
      </init-param>
  </init-params>
</password-provider>
----
In the snippet above the password file location will be passed in using the
`coherence.tls.keystore.password` system property.

We declare another password provider for the private key password.

We then declare the configuration for the truststore, which follows the same pattern as the keystore.

The configuration above is included in both of the example images that we built above.

[#tcmp]
== Secure Cluster Membership

Now we have a "tls" socket provider we can use it to secure Coherence. The Coherence documentation has a section on https://docs.oracle.com/en/middleware/standalone/coherence/14.1.1.0/secure/using-ssl-secure-communication.html#GUID-21CBAF48-BA78-4373-AC90-BF668CF31776[Securing Coherence TCMP with TLS].
Securing communication between cluster members is very simple, we just set the `coherence.socketprovider` system property to the name of the socket provider we want to use. In our case this will be the "tls" provider we configured above, so we would use `-Dcoherence.socketprovider=tls`

The yaml below is a `Coherence` resource that will cause the Operator to create a three member Coherence cluster.

[source,yaml]
.manifests/coherence-cluster.yaml
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: tls-cluster
spec:
  replicas: 3
  image: tls-example-server:1.0.0    # <1>
  cluster: test-cluster              # <2>
  coherence:
    overrideConfig: tls-coherence-override.xml  # <3>
    cacheConfig: server-cache-config.xml        # <4>
  jvm:
    args:
      - -Dcoherence.socketprovider=tls  # <5>
      - -Dcoherence.tls.keystore=file:/coherence/certs/keystore.jks
      - -Dcoherence.tls.keystore.password=file:/coherence/certs/credentials/password-key
      - -Dcoherence.tls.key.password=file:/coherence/certs/credentials/password-key
      - -Dcoherence.tls.truststore=file:/coherence/certs/truststore.jks
      - -Dcoherence.tls.truststore.password=file:/coherence/certs/credentials/password-key
  secretVolumes:
    - mountPath: coherence/certs             # <6>
      name: coherence-server-certs
    - mountPath: coherence/certs/credentials
      name: server-keystore-secret
  ports:
    - name: extend  # <7>
      port: 20000
    - name: grpc
      port: 1408
    - name: management
      port: 30000
    - name: metrics
      port: 9612
----

<1> The image name is the server image built from this example project

<2> We specify a cluster name because we want to be able to demonstrate other Coherence deployments can or cannot join this cluster, so their yaml files will use this same cluster name.

<3> We set the Coherence override file to the file containing the "tls" socket provider configuration.

<4> We use a custom cache configuration file that has an Extend proxy that we can secure later.

<5> We set the `coherence.socketprovider` system property to use the "tls" provider, we also set a number of other properties that will set the locations of the keystores and password files to map to the secret volume mounts.

<6> We mount the certificate and password secrets to volumes

<7> We expose some ports for clients which we will use later, and for management, so we can enquire on the cluster state using REST.

Install the yaml above into the `coherence-test` namespace:

[source,bash]
----
kubectl -n coherence-test apply -f manifests/coherence-cluster.yaml
----

If we list the Pods in the `coherence-test` namespace then after a minute or so there should be three ready Pods.

[source,bash]
----
kubectl -n coherence-test get pods
----

[source,bash]
----
NAME             READY   STATUS    RESTARTS   AGE
tls-cluster-0    1/1     Running   0          88s
tls-cluster-1    1/1     Running   0          88s
tls-cluster-2    1/1     Running   0          88s
----

=== Port Forward to the REST Management Port

Remember that we exposed a number of ports in our Coherence cluster, one of these was REST management on port `30000`.
We can use this along with `curl` to enquire about the cluster state.
We need to use `kubectl` to forward a local port to one of the Coherence Pods.

Open another terminal session and run the following command:
[source,bash]
----
kubectl -n coherence-test port-forward tls-cluster-0 30000:30000
----
This will forward port `30000` on the local machine (e.g. your dev laptop) to the `tls-cluster-0` Pod.

We can now obtain the cluster state from the REST endpoint with the following command:
[source,bash]
----
curl -X GET http://127.0.0.1:30000/management/coherence/cluster
----
or if you have the https://stedolan.github.io/jq/[jq] utility we can pretty print the json output:
[source,bash]
----
curl -X GET http://127.0.0.1:30000/management/coherence/cluster | jq
----

We will see json something like this:
[source,json]
----
{
  "links": [
  ],
  "clusterSize": 3,      <1>
  "membersDeparted": [],
  "memberIds": [
    1,
    2,
    3
  ],
  "oldestMemberId": 1,
  "refreshTime": "2021-03-07T12:27:20.193Z",
  "licenseMode": "Development",
  "localMemberId": 1,
  "version": "21.06",
  "running": true,
  "clusterName": "test-cluster",
  "membersDepartureCount": 0,
  "members": [                     <2>
    "Member(Id=1, Timestamp=2021-03-07 12:24:32.982, Address=10.244.1.6:38271, MachineId=17483, Location=site:zone-two,rack:two,machine:operator-worker2,process:33,member:tls-cluster-1, Role=tls-cluster)",
    "Member(Id=2, Timestamp=2021-03-07 12:24:36.572, Address=10.244.2.5:36139, MachineId=21703, Location=site:zone-one,rack:one,machine:operator-worker,process:35,member:tls-cluster-0, Role=tls-cluster)",
    "Member(Id=3, Timestamp=2021-03-07 12:24:36.822, Address=10.244.1.7:40357, MachineId=17483, Location=site:zone-two,rack:two,machine:operator-worker2,process:34,member:tls-cluster-2, Role=tls-cluster)"
  ],
  "type": "Cluster"
}
----

<1> We can see that the cluster size is three.
<2> The member list shows details of the three Pods in the cluster


=== Start Non-TLS Cluster Members

To demonstrate that the cluster is secure we can start another cluster with yaml that does not enable TLS.

[source,yaml]
.manifests/coherence-cluster-no-tls.yaml
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: no-tls-cluster
spec:
  replicas: 3
  image: tls-example-server:1.0.0     # <1>
  cluster: test-cluster               # <2>
  coherence:
    cacheConfig: server-cache-config.xml
  ports:
    - name: extend
      port: 20000
    - name: grpc
      port: 1408
    - name: management
      port: 30000
    - name: metrics
      port: 9612
----

<1> This `Coherence` resource uses the same server image as the secure cluster

<2> This `Coherence` resource also uses the same cluster name as the secure cluster, `test-cluster`, so it should attempt to join with the secure cluster.
If the existing cluster is not secure, we will end up with a cluster of six members.


Install the yaml above into the `coherence-test` namespace:

[source,bash]
----
kubectl -n coherence-test apply -f manifests/coherence-cluster-no-tls.yaml
----

If we list the Pods in the `coherence-test` namespace then after a minute or so there should be three ready Pods.

[source,bash]
----
kubectl -n coherence-test get pods
----

[source,bash]
----
NAME                READY   STATUS    RESTARTS   AGE
tls-cluster-0       1/1     Running   0          15m
tls-cluster-1       1/1     Running   0          15m
tls-cluster-2       1/1     Running   0          15m
no-tls-cluster-0    1/1     Running   0          78s
no-tls-cluster-1    1/1     Running   0          78s
no-tls-cluster-2    1/1     Running   0          78s
----

There are six pods running, but they have not formed a six member cluster.
If we re-run the curl command to query the REST management endpoint of the secure cluster we will see that the cluster size is still three:

[source,bash]
----
curl -X GET http://127.0.0.1:30000/management/coherence/cluster -s | jq '.clusterSize'
----

What happens is that the non-TLS members have effectively formed their own cluster of three members, but have not been able to form a cluster with the TLS enabled members.


=== Cleanup

After trying the example, remove both clusters with the corresponding `kubectl delete` commands so that they do not interfere with the next example.

[source,bash]
----
kubectl -n coherence-test delete -f manifests/coherence-cluster-no-tls.yaml

kubectl -n coherence-test delete -f manifests/coherence-cluster.yaml
----

[#extend]
=== Secure Extend Connections

A common connection type to secure are client connections into the cluster from Coherence Extend clients. The Coherence documentation contains details on https://docs.oracle.com/en/middleware/standalone/coherence/14.1.1.0/secure/using-ssl-secure-communication.html#GUID-0F636928-8731-4228-909C-8B8AB09613DB[Using SSL to Secure Extend Client Communication] for more in-depth details.

As with securing TCMP, we can specify a socket provider in the Extend proxy configuration in the server's cache configuration file and also in the remote scheme in the client's cache configuration. In this example we will use exactly the same TLS socket provider configuration that we created above. The only difference being the name of the `PasswordProvider` class used by the client. At the time of writing this, Coherence does not include an implementation of `PasswordProvider` that reads from a file. The Coherence Operator injects one into the classpath of the server, but our simple client is not managed by the Operator. We have added a simple `FileBasedPasswordProvider` class to the client code in this example.

==== Secure the Proxy

To enable TLS for an Extend proxy, we can just specify the name of the socket provider that we want to use in the `<proxy-scheme>` in the server's cache configuration file.

The snippet of configuration below is taken from the `server-cache-config.xml` file in the example source.

[source,xml]
.src/main/resources/server-cache-config.xml
----
<proxy-scheme>
    <service-name>Proxy</service-name>
    <acceptor-config>
        <tcp-acceptor>
            <socket-provider system-property="coherence.extend.socket.provider"/>       <1>
            <local-address>
                <address system-property="coherence.extend.address">0.0.0.0</address>   <2>
                <port system-property="coherence.extend.port">20000</port>              <3>
            </local-address>
        </tcp-acceptor>
    </acceptor-config>
    <load-balancer>client</load-balancer>
    <autostart>true</autostart>
</proxy-scheme>
----

<1> The `<socket-provider>` element is empty by default, but is configured to be set from the system property named `coherence.extend.socket.provider`. This means that by default, Extend will run without TLS. If we start the server with the system property set to "tls", the name of our socket provider, then the proxy will use TLS.
<2> The Extend proxy will bind to all local addresses.
<3> The Extend proxy service will bind to port 20000.

We add the additional `coherence.extend.socket.provider` system property to the `spec.jvm.args` section of the Coherence resource yaml we will use to deploy the server. The yaml below is identical to the yaml we used above to secure TCMP, but with the addition of the `coherence.extend.socket.provider` property.

[source,yaml]
.coherence-cluster-extend.yaml
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: tls-cluster
spec:
  replicas: 3
  image: tls-example-server:1.0.0
  cluster: test-cluster
  coherence:
    cacheConfig: server-cache-config.xml
    overrideConfig: tls-coherence-override.xml
  jvm:
    args:
      - -Dcoherence.socketprovider=tls
      - -Dcoherence.extend.socket.provider=tls    # <1>
      - -Dcoherence.tls.keystore=file:/coherence/certs/keystore.jks
      - -Dcoherence.tls.keystore.password=file:/coherence/certs/credentials/password-key
      - -Dcoherence.tls.key.password=file:/coherence/certs/credentials/password-key
      - -Dcoherence.tls.truststore=file:/coherence/certs/truststore.jks
      - -Dcoherence.tls.truststore.password=file:/coherence/certs/credentials/password-key
  secretVolumes:
    - mountPath: coherence/certs
      name: coherence-server-certs
    - mountPath: coherence/certs/credentials
      name: server-keystore-secret
  ports:
    - name: extend
      port: 20000
    - name: grpc
      port: 1408
----

<1> The `-Dcoherence.extend.socket.provider=tls` has been added to enable TLS for the Extend proxy.

Installing the yaml above will give us a Coherence cluster that uses TLS for both TCMP inter-cluster communication and for Extend connections.

==== Install the Cluster

We can install the Coherence cluster defined in the yaml above using `kubectl`:

[source,bash]
----
kubectl -n coherence-test apply -f manifests/coherence-cluster-extend.yaml
----

After a minute or two the three Pods should be ready, which can be confirmed with `kubectl`.
Because the yaml above declares a port named `extend` on port `20000`, the Coherence Operator will create a k8s `Service` to expose this port. The service name will be the Coherence resource name suffixed with the port name, so in this case `tls-cluster-extend`. As a `Service` in k8s can be looked up by DNS, we can use this service name as the host name for the client to connect to.

==== Configure the Extend Client

Just like the server, we can include a socket provider configuration in the override file and configure the name of the socket provider that the client should use in the client's cache configuration file. The socket provider configuration is identical to that shown already above (with the different `FileBasedPasswordProvider` class name).

The Extend client code used in the `src/main/java/com/oracle/coherence/examples/k8s/client/Main.java` file in this example just starts a Coherence client, then obtains a `NamedMap`, and in a very long loop just puts data into the map, logging out the keys added. This is very trivial but allows us to see that the client is connected and working (or not).

The snippet of xml below is from the client's cache configuration file.

[source,xml]
.src/main/resources/client-cache-config.xml
----
<remote-cache-scheme>
    <scheme-name>remote</scheme-name>
    <service-name>Proxy</service-name>
    <initiator-config>
        <tcp-initiator>
            <socket-provider system-property="coherence.extend.socket.provider"/>           <1>
            <remote-addresses>
                <socket-address>
                    <address system-property="coherence.extend.address">127.0.0.1</address> <2>
                    <port system-property="coherence.extend.port">20000</port>              <3>
                </socket-address>
            </remote-addresses>
        </tcp-initiator>
    </initiator-config>
</remote-cache-scheme>
----

<1> The `<socket-provider>` element is empty by default, but is configured to be set from the system property named `coherence.extend.socket.provider`. This means that by default, the Extend client will connect without TLS. If we start the client with the system property set to "tls", the name of our socket provider, then the client will use TLS.

<2> By default, the Extend client will connect loopback, on `127.0.0.1` but this can be overridden by setting the `coherence.extend.address` system property. We will use this when we deploy the client to specify the name of the `Service` that is used to expose the server's Extend port.

<3> The Extend client will connect to port 20000. Although this can be overridden with a system property, port 20000 is also the default port used by the server, so there is no need to override it.

==== Start an Insecure Client

As a demonstration we can first start a non-TLS client and see what happens. We can create a simple `Pod` that will run the client image using the yaml below.

One of the features of newer Coherence CE versions is that configuration set via system properties prefixed with `coherence.` can also be set with corresponding environment variable names. The convention used for the environment variable name is to convert the system property name to uppercase and convert "." characters to "_", so setting the cache configuration file with the `coherence.cacheconfig` system property can be done using the `COHERENCE_CACHECONFIG` environment variable.
This makes it simple to set Coherence configuration properties in a Pod yaml using environment variables instead of having to build a custom Java command line.

[source,yaml]
.manifests/client-no-tls.yaml
----
apiVersion: v1
kind: Pod
metadata:
  name: client
spec:
  containers:
    - name: client
      image: tls-example-client:1.0.0
      env:
        - name: COHERENCE_CACHECONFIG       # <1>
          value: client-cache-config.xml
        - name: COHERENCE_EXTEND_ADDRESS    # <2>
          value: tls-cluster-extend
----

<1> The client will use the `client-cache-config.xml` cache configuration file.
<2> The `COHERENCE_EXTEND_ADDRESS` is set to `tls-cluster-extend`, which is the name of the service exposing the server's Extend port and which will be injected into the client's cache configuration file, as explained above.

We can run the client Pod with the following command:
[source,bash]
----
kubectl -n coherence-test apply -f manifests/client-no-tls.yaml
----

If we look at the Pods now in the `coherence-test` namespace we will see the client running:
[source,bash]
----
$ kubectl -n coherence-test get pod
----

[source,bash]
----
NAME            READY   STATUS    RESTARTS   AGE
client          1/1     Running   0          3s
tls-cluster-0   1/1     Running   0          2m8s
tls-cluster-1   1/1     Running   0          2m8s
tls-cluster-2   1/1     Running   0          2m8s
----

If we look at the log of the client Pod though we will see a stack trace with the cause:
[source,bash]
----
kubectl -n coherence-test logs client
----

[source]
----
2021-03-07 12:53:13.481/1.992 Oracle Coherence CE 21.06 <Error> (thread=main, member=n/a): Error while starting service "Proxy": com.tangosol.net.messaging.ConnectionException: could not establish a connection to one of the following addresses: []
----
This tells us that the client failed to connect to the cluster, because the client is not using TLS.

We can remove the non-TLS client:
[source]
----
kubectl -n coherence-test delete -f manifests/client-no-tls.yaml
----

==== Start a TLS Enabled Client

We can now modify the client yaml to run the client with TLS enabled.
The client image already contains the `tls-coherence-override.xml` file with the configuration for the TLS socket provider.
We need to set the relevant environment variables to inject the location of the keystores and tell Coherence to use the "tls" socket provider for the Extend connection.

[source,yaml]
.manifests/client.yaml
----
apiVersion: v1
kind: Pod
metadata:
  name: client
spec:
  containers:
    - name: client
      image: tls-example-client:1.0.0
      env:
        - name: COHERENCE_CACHECONFIG
          value: client-cache-config.xml
        - name: COHERENCE_EXTEND_ADDRESS
          value: tls-cluster-extend
        - name: COHERENCE_OVERRIDE
          value: tls-coherence-override.xml                 # <1>
        - name: COHERENCE_EXTEND_SOCKET_PROVIDER
          value: tls
        - name: COHERENCE_TLS_KEYSTORE
          value: file:/coherence/certs/keystore.jks
        - name: COHERENCE_TLS_KEYSTORE_PASSWORD
          value: /coherence/certs/credentials/password-key
        - name: COHERENCE_TLS_KEY_PASSWORD
          value: /coherence/certs/credentials/password-key
        - name: COHERENCE_TLS_TRUSTSTORE
          value: file:/coherence/certs/truststore.jks
        - name: COHERENCE_TLS_TRUSTSTORE_PASSWORD
          value: /coherence/certs/credentials/password-key
      volumeMounts:                                         # <2>
        - name: coherence-client-certs
          mountPath: coherence/certs
        - name: keystore-credentials
          mountPath: coherence/certs/credentials
  volumes:                                                  # <3>
    - name: coherence-client-certs
      secret:
        defaultMode: 420
        secretName: coherence-client-certs
    - name: keystore-credentials
      secret:
        defaultMode: 420
        secretName: client-keystore-secret
----

<1> The yaml is identical to the non-TLS client with the addition of the environment variables to configure TLS.
<2> We create volume mount points to map the Secret volumes containing the keystores and password to directories in the container
<3> We mount the Secrets as volumes

We can run the client Pod with the following command:
[source,bash]
----
kubectl -n coherence-test apply -f manifests/client.yaml
----

If we now look at the client's logs:
[source,bash]
----
kubectl -n coherence-test logs client
----
The end of the log should show the messages from the client as it puts each entry into a `NamedMap`.
[source]
----
Put 0
Put 1
Put 2
Put 3
Put 4
Put 5
----

So now we have a TLS secured Extend proxy and client.
We can remove the client and test cluster:

[source,bash]
----
kubectl -n coherence-test delete -f manifests/client.yaml

kubectl -n coherence-test delete -f manifests/coherence-cluster-extend.yaml
----




///////////////////////////////////////////////////////////////////////////////

    Copyright (c) 2019 Oracle and/or its affiliates. All rights reserved.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

///////////////////////////////////////////////////////////////////////////////

= Configure the JVM

== Configure the JVM

There are a number of fields in the `CoherenceCluster` CRD that can be used to configure the JVM.
These fields are all in the `jvm` section when configuring a `role` in the CRD.

* <<#args,JVM Arguments>>
* <<#gc,Garbage Collector Configuration>>
** <<#gc-collector,Configuring the Garbage Collector to Use>>
** <<#gc-args,Configuring the Garbage Collector Arguments>>
** <<#gc-logging,Configuring Garbage Collector Logging>>
* <<#memory,Memory Configuration>>
** <<#heap-size,Heap Size>>
** <<#metaspace-size,Metaspace size>>
** <<#stack-size,Stack size>>
** <<#nio-size,Native Memory Size>>
** <<#nmt,Native Memory Tracking>>
* <<#oom,Behaviour on Out Of Memory Error>>
* <<#jmx,JMX Management>>
* <<#useContainerLimits,Container Resource Limits>>
* <<#flightRecorder,Flight Recorder>>
* <<#diagnosticsVolume,Diagnostic Volume>>
* <<debug#,JVM Debug Arguments>>

The following sections describe the different JVM configuration options available in the `CoherenceCluster` CRD.
These CRD fields all result in the addition or omission of various JVM arguments.
A number of arguments are always passed to the Coherence container's JVM:

```
-XX:HeapDumpPath=/jvm/${POD_NAME}/${POD_UID}/heap-dumps/${POD_NAME}-${POD_UID}.hprof  <1>
-XX:ErrorFile=/jvm/${POD_NAME}/${POD_UID}/hs-err-${POD_NAME}-${POD_UID}.log           <2>
-Dcoherence.ttl=0                                                                     <3>
-XshowSettings:all
-XX:+PrintCommandLineFlags
-XX:+PrintFlagsFinal
-XX:+UnlockDiagnosticVMOptions
-XX:+UnlockCommercialFeatures
-XX:+UnlockExperimentalVMOptions
```

<1> Any heap dumps created by the JVM when an out of memory error occurs will be written to a file called
`/jvm/${POD_NAME}/${POD_UID}/heap-dumps/${POD_NAME}-${POD_UID}.hprof`
<2> Any error files created by a JVM crash will be written to a file called
`/jvm/${POD_NAME}/${POD_UID}/hs-err-${POD_NAME}-${POD_UID}.log`
<3> Coherence multicast discovery is disabled as multicast cannot be relied on in containers

The `/jvm` root directory used for heap dumps and error files can be
<<#diagnosticsVolume,mounted to an external volume>> to allow easier access to these files.


// ----- JVM Arguments -------------------------------------------------------------------------------------------------
'''
[#args]
== JVM Arguments

The `jvm.args` field is a string array of arbitrary JVM options. Any valid JVM option or system property argument may be
passed to the JVM in the Coherence container by setting the value in this field.

=== Setting the JVM Arguments for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role the `args` is set in the `spec.jvm` section of
the configuration. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    args:
      - "-XX:G1HeapRegionSize=16m"  # <1>
      - "-Dfoo=bar" 
----

<1> The `-XX:G1HeapRegionSize=16m` JVM option and the `-Dfoo=bar` system property will be passed as arguments to the 
JVM for the implicit storage role.


=== Setting the JVM Arguments for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles the `args` are set in the `jvm` section of
the configuration for each `role` in the `roles` list. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        args:
          - "-XX:G1HeapRegionSize=16m"  # <1>
          - "-Dcoherence.pof.config=storage-pof-config.xml"
    - role: proxy
      jvm:
        args:
          - "-XX:MaxGCPauseMillis=500"  # <2>
          - "-Dcoherence.pof.config=proxy-pof-config.xml"
----

<1> The `-XX:G1HeapRegionSize=16m -Dcoherence.pof.config=storage-pof-config.xml` arguments will be passed to the JVM for
the explicit `data` role.
<2> The `-XX:MaxGCPauseMillis=500 coherence.pof.config=proxy-pof-config.xml` argument will be passed to the JVM for the
explicit `proxy` role.


=== Setting the JVM Arguments for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default `args` value can be set in the
`CoherenceCluster` `spec` section that will apply to all of the roles in the `roles` list.

NOTE: Any `args` set explicitly in the `jvm.args` field for a `role` will be *merged* with those in the defaults
section.

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    args:
      - "-XX:MaxGCPauseMillis=500"  # <1>
      - "-XX:G1HeapRegionSize=16m" 
  roles:
    - role: data                    # <2>
      jvm:
        args:
          - "-XX:+AggressiveHeap"
    - role: proxy                   # <3>
----

<1> The default JVM `args` of `-XX:MaxGCPauseMillis=500` and `-XX:G1HeapRegionSize=16m` will be passed to the JVM
for *all* roles.
<2> The `data` role adds an additional argument `-XX:+AggressiveHeap` so the JVM will be passed three arguments:
`-XX:MaxGCPauseMillis=500 -XX:G1HeapRegionSize=16m -XX:+AggressiveHeap`
<3> The `proxy` role does not specify any additional args so will just use the two default JVM arguments
`-XX:MaxGCPauseMillis=500 -XX:G1HeapRegionSize=16m`


// ----- Garbage Collector Configuration -------------------------------------------------------------------------------
'''
[#gc]
== Garbage Collector Configuration

The `CoherenceCluster` CRD allows garbage collector settings to be applied to the Coherence JVMs. Whilst any GC
parameters could actually be applied using the `jvm.args` field these GC specific fields allow options to be set
without having to look up and remember specific GC options. The garbage collector configuration is set in the
`jvm.gc` section of the CRD.

* <<#gc-collector,Configuring the Garbage Collector to Use>>
* <<#gc-args,Configuring the Garbage Collector Arguments>>
* <<#gc-logging,Configuring Garbage Collector Logging>>

// ----- Garbage Collector ---------------------------------------------------------------------------------------------

[#gc-collector]
=== Configuring the Garbage Collector to Use

The `CoherenceCluster` CRD supports setting the garbage collectors to use automatically. The supported collectors are
`G1`, `CMS`, `Parallel` or the JVM default.
The garbage collector to use is set using the `jvm.gc.collector` field.
The value sould be one of:

[cols=2*,options=header]
|===
|Value
|Description

|`G1`
|Enables the G1 garbage collector by adding the `-XX:+UseG1GC` JVM option

|`CMS`
|Enables the CMS garbage collector by adding the `-XX:+UseConcMarkSweepGC` JVM option

|`Parallel`
|Enables the parallel garbage collector by adding the `-XX:+UseParallelGC` JVM option

|`Default`
|Deos not add any extra GC parameter; the JVM will use its default garbage collector

...
|===

The `jvm.gc.collector` value is not case sensitive so for example `CMS`, `cms` and `CmS` will all enable the `CMS`
collector.
The contents of the `jvm.gc.collector` are not validated, any value other than those described above will be treated
as `Default` enabling the JVMs default garbage collector.

NOTE: The default value for `jvm.gc.collector` is `G1` which will enable the recommended G1 garbage collector.

==== Setting the Garbage Collector for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role the garbage collector to use is set in the `spec`
section of the yaml. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    gc:
      collector: CMS  # <1>
----

The implicit storage role will use the `CMS` garbage collector.

==== Setting the Garbage Collector for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles the garbage collector to use is set in the
`jvm.gc.collector` section for each role.

For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        gc:
          collector: G1   # <1>
    - role: proxy
      jvm:
        gc:
          collector: CMS  # <2>
----

<1> The JVMs for the `data` role will use the G1 garbage collector
<2> The JVMs for the `proxy` role will use the CMS garbage collector


==== Setting the Garbage Collector for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default garbage collector can be set in the
`spec.jvm.gc.collector` field of the CRD. This value can then be overridden for specific roles in the `jvm.gc.collector`
field for each role in the `roles` list.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    gc:
      collector: CMS     # <1>
  roles:
    - role: data         # <2>
      jvm:
        gc:
          collector: G1
    - role: proxy        # <3>
----

<1> The default garbage collector us set to `CMS` which will be used by all roles in the `roles` list that do not
set a specific collector to use.
<2> The `data` role overrides the default collector so that the JVMs for the `data` role will use the G1 garbage
collector
<3> The `proxy` role does not specify a collector to use so that JVMs for the `proxy` role will use the CMS garbage
collector


// ----- Garbage Collector Arguments -----------------------------------------------------------------------------------

[#gc-args]
=== Configuring Garbage Collector Arguments

Arbitrary GC arguments can be passed to the JVM in the `jvm.gc.args` field. This field is a string array where each
argument to be passed to the JVM is a separate string value.

==== Setting Garbage Collector Arguments for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role the GC arguments are set in the `spec.jvm.gc.args` field.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    gc:
      args:                           # <1>
        - "-XX:MaxGCPauseMillis=500"
        - "-XX:G1ReservePercent=20"
----

<1> The implicit storage role will have the additional GC arguments `-XX:MaxGCPauseMillis=500` and
`-XX:G1ReservePercent=20` passed to the JVM.

==== Setting Garbage Collector Arguments for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles the GC arguments are set in the `jvm.gc.args` field
for each role in the `roles` list.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        gc:
          args:                            # <1>
            - "-XX:MaxGCPauseMillis=500"
            - "-XX:G1ReservePercent=20"
    - role: proxy
      jvm:
        gc:
          args:                            # <2>
            - "-XX:MaxGCPauseMillis=1000"
----

<1> The explicit `data` role will have the additional GC arguments `-XX:MaxGCPauseMillis=500` and
`-XX:G1ReservePercent=20` passed to the JVM.
<2> The explicit `proxy` role will have the additional GC argument `-XX:MaxGCPauseMillis=1000` passed to the JVM.


==== Setting Garbage Collector Arguments for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default GC arguments are set in the
`spec.jvm.gc.args` field and will be applied to all roles in the roles list that do not set specific GC arguments.

NOTE: GC arguments set for explicit roles override the defaults. The role's GC arguments are *not merged* with the
default GC arguments.

For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    gc:
      args:                                # <1>
        - "-XX:MaxGCPauseMillis=500"
        - "-XX:G1ReservePercent=20"
  roles:
    - role: data                           # <2>
    - role: proxy
      jvm:
        gc:
          args:                            # <3>
            - "-XX:MaxGCPauseMillis=1000"
----

<1> The default GC arguments are `-XX:MaxGCPauseMillis=500` and `-XX:G1ReservePercent=20`
<2> The `data` role does not specify any GC arguments so the default arguments of `-XX:MaxGCPauseMillis=500` and
`-XX:G1ReservePercent=20` will be passed to the `data` role JVMs.
<3> The `proxy` role specifies the GC arguments `-XX:MaxGCPauseMillis=1000` which will *override* the defaults so only
`-XX:MaxGCPauseMillis=1000` will be passed to the `proxy` role JVMs.


// ----- Garbage Collector Logging -------------------------------------------------------------------------------------

[#gc-logging]
=== Configuring Garbage Collector Logging

The Coherence documentation recommends enabling GC logging for Coherence JVMs. To this end the `CoherenceCluster` CRD
has a boolean field `jvm.gc.logging` to enable or disable default GC logging JVM arguments. By default the value of this
field is set to `true` if it is not specified for a `CoherenceCluster`.

The following GC logging JVM arguments are added if the `jvm.gc.logging` field is omitted or explicitly set to `true`:
```
-verbose:gc
-XX:+PrintGCDetails
-XX:+PrintGCTimeStamps
-XX:+PrintHeapAtGC
-XX:+PrintTenuringDistribution
-XX:+PrintGCApplicationStoppedTime
-XX:+PrintGCApplicationConcurrentTime
```

==== Configuring Garbage Collector Logging for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role GC logging can be enabled or disabled in the `spec`
section of the yaml.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    gc:
      logging: true  # <1>
----

<1> The implicit storage role has GC logging explicitly enabled so that the JVM arguments listed above will
be added to the JVM's command line.


==== Configuring Garbage Collector Logging for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles GC logging can be enabled or disabled in the
`jvm.gc.logging` field of each role in the `roles` list.
section of the yaml
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        gc:
          logging: true   # <1>
    - role: proxy
      jvm:
        gc:
          logging: false  # <2>
----

<1> The `data` role has GC logging explicitly enabled so that the JVM arguments listed above will be added to the
JVM's command line
<2> The `proxy` role has GC logging explicitly disabled so that the JVM arguments listed above will not be added to
the JVM's command line


==== Configuring Garbage Collector Logging for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default GC logging setting can be specified in the
`spec` section of the CRD which can then be overridden for individual roles in the `roles` list.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    gc:
      logging: false      # <1>
  roles:
    - role: data          # <2>
      jvm:
        gc:
          logging: true
    - role: proxy         # <3>
----

<1> The default value for `jvm.gc.logging` is false, which will disable GC logging.
<2> The `data` role overrides the default and sets GC logging to `true`
<3> The `proxy` role does not specify a value for `jvm.gc.logging` so it will use the default, which will disable GC
logging.

// ----- Memory Configuration ------------------------------------------------------------------------------------------
'''
[#memory]
== Memory Configuration

The JVM has a number of options that can be set to fix the size of different memory regions. The `CoherenceCluster` CRD
provides fields to set that most common values. None of these fields have default values so if they are not specified
the JVMs default behaviour will apply.

The memory options that can be configured are:

* <<#heap-size,Heap Size>>
* <<#metaspace-size,Metaspace size>>
* <<#stack-size,Stack size>>
* <<#nio-size,Max Native Memory>>
* <<#nmt,Native Memory Tracking>>
* <<#oom,Behaviour on Out Of Memory Error>>

NOTE: If the `Pod` resource limits are being set to limit memory usage of a `Pod` it is recommended that some of the JVM
memory regions are fixed to ensure that the JVM does not exceed the container's resource limits in a JVM before Java 10.
Prior to Java 10 the JVM could see all of the memory available to a machine regardless of any Pod limits.
The JVM could then easily attempt to consume more memory that the `Pod` or `Container` was allowed and consequently
crashing the `Pod`. With Coherence images that use a version of Java above 10 this issue is less of a problem.
Even so if using the `resources` section of the configuration to limit a `Pod` or `Containers` memory it is a good idea
to limit the JVM heap. Also see <<#useContainerLimits,the useContainerLimits setting>>.


// ----- Heap Size -----------------------------------------------------------------------------------------------------

[#heap-size]
=== JVM Heap Size

It is good practice to fix the Coherence JVM heap size and to set both the JVM `-Xmx` and `-Xms` options to the same
value.
The heap size of the JVM can be configured for roles in the `jvm.heapSize` field of a role spec. If the `heapSize` value
is configured then that value is applied to bot the JVMs minimum and maximum heap sizes (i.e. used to set both
`-Xms` and -`Xmx`).

The format of the value of the `heapSize` field is any valid value that can be used when setting the `-Xmx` JVM option,
for example `10G` would set a 10 GB heap.

==== Setting the JVM Heap Size for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role the `heapSize` is set in the `spec.jvm` section of
the configuration. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      heapSize: 10g # <1>
----

<1> The Coherence JVM for the implicit role defined above will have a 10 GB heap.
Equivalent to passing `-Xms10g -Xmx10g` to the JVM.


==== Setting the JVM Heap Size for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles the `heapSize` is set in the `jvm` section of
the configuration for each `role` in the `roles` list. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        memory:
          heapSize: 10g   # <1>
    - role: proxy
      jvm:
        memory:
          heapSize: 500m  # <2>
----

<1> The Coherence JVM for the `data` role defined above will have a 10 GB heap.
Equivalent to passing `-Xms10g -Xmx10g` to the JVM.
<2> The Coherence JVM for the `proxy` role defined above will have a 500 MB heap.
Equivalent to passing `-Xms500m -Xmx500m` to the JVM.


==== Setting the JVM Heap Size for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default `heapSize` value can be set in the
`CoherenceCluster` `spec` section that will apply to all of the roles in the `roles` list unless specifically
overridden by a role's `jvm.heapSize` field. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      heapSize: 500m     # <1>
  roles:
    - role: data
      jvm:
        memory:
          heapSize: 10g  # <2>
    - role: proxy        # <3>
    - role: web          # <4>
----

<1> The default max heap size of 500 MB will be applied to all of the roles in the cluster unless overridden for a
specific role.
<2> The `data` role overrides the default value to set the max heap for all JVMs in the `data` role to 10 GB.
Equivalent to passing `-Xms10g -Xmx10g` to the JVM.
<3> The `proxy` role does not specify a `heapSize` value so it will use the default value of 500 MB.
<4> The `web` role does not specify a `heapSize` value so it will use the default value of 500 MB.


// ----- Metaspace Size ------------------------------------------------------------------------------------------------

[#metaspace-size]
=== JVM Metaspace Size

The metaspace size is the amount of native memory that can be allocated for class metadata. By default the JVM does not
limit this size. When running in size limited containers this size may be set to ensure that the JVM does not cause the
container to exceed its configured memory limits. The metaspace size is set using the `jvm.memory.metaspaceSize` field.
Setting this field causes the `-XX:MetaspaceSize` and `-XX:MaxMetaspaceSize` JVM arguments to be set.
There is no default value for the `metaspaceSize` field so if it is omitted the JVMs default behaviour will control the
metaspace size.

==== Configuring the JVM Metaspace Size for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role the metaspace size can be set in the `spec` section of
the CRD.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      metaspaceSize: 256m  # <1>
----

<1> The metaspace size will for the implicit storage role will be set to `256m` by setting the JVM arguments
`-XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m`

==== Configuring the JVM Metaspace Size for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles the metaspace size can be set in the
`jvm.memory.metaspaceSize` field for each role in the `roles` list.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        memory:
          metaspaceSize: 256m  # <1>
    - role: proxy
      jvm:
        memory:
          metaspaceSize: 512m  # <2>
----

<1> The metaspace size will for the `data` role will be set to `256m` by setting the JVM arguments
`-XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m`
<2> The metaspace size will for the `proxy` role will be set to `512m` by setting the JVM arguments
`-XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m`


==== Configuring the JVM Metaspace Size for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      metaspaceSize: 512m      # <1>
  roles:
    - role: data               # <2>
      jvm:
        memory:
          metaspaceSize: 256m
    - role: proxy              # <3>
----

<1> The metaspace size will for the `data` role will be set to `256m` by setting the JVM arguments
`-XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m`
<2> The metaspace size will for the `proxy` role will be set to `512m` by setting the JVM arguments
`-XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m`


// ----- Stack Size ----------------------------------------------------------------------------------------------------

[#stack-size]
=== JVM Stack Size

Setting the stack size sets the thread stack size (in bytes) used by the JVM. The stack size is configured in for roles
in a `CoherenceCluster` by setitng the `jvm.memory`stackSize` field. Setting this fields sets the `-Xss` JVM argument.
Omitting this fields does not set the `-Xss` argument leaving the JVM to its default configuration which sets the stack
size based on the O/S being used.

==== Configuring the JVM Stack Size for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role the stack size can be set in the `spec` section of CRD.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      stackSize: 1024k  # <1>
----

<1> The stack size for the implicit storage role is set to `1024k` which will cause the `-Xss1024k` argument to be
passed to the JVM.

==== Configuring the JVM Stack Size for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        memory:
          stackSize: 512k   # <1>
    - role: proxy
      jvm:
        memory:
          stackSize: 1024k  # <2>
----

<1> The stack size for the `data` role is set to `512k` which will cause the `-Xss512k` argument to be passed to the JVM.
<2> The stack size for the `proxy` role is set to `1024k` which will cause the `-Xss1024k` argument to be passed to the JVM.


==== Configuring the JVM Stack Size for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default stack size can be set in the `spec` section
of the yaml that will apply to all roles in the `roles` list unless overridden for a specific role.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      stackSize: 1024k      # <1>
  roles:
    - role: data            # <2>
      jvm:
        memory:
          stackSize: 512k
    - role: proxy           # <3>
----

<1> The default stack size is set to `1024k` which will cause the `-Xss1024k` argument to be passed to the JVM for all
roles in the `roles` list unless overridden.
<2> The stack size for the `data` role is specifically set to `512k` which will cause the `-Xss512k` argument to be passed
to the JVMs for the `data` role.
<3> The stack size for the `proxy` role is not configured so the default value will be used which will cause the
`-Xss1024k` argument to be passed to the JVMs for the `proxy` role.


// ----- Native Memory Size --------------------------------------------------------------------------------------------

[#nio-size]
=== JVM Native Memory Size

Native memory is used by the JVM and by Coherence for a number of reasons. In a resource limited container it may be
useful to limit the amount of nio memory available to the JVM to stop the JVM exceeding the containers memory limits.
The nio size is set using the `jvm.directMemorySize` field which will cause the `-XX:MaxDirectMemorySize` JVM argument
to be set. There is no default value for the `jvm.directMemorySize` field so if it is omitted the JVM's default size
will be used.

==== Configuring the JVM Native Memory Size for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      directMemorySize: 2g  # <1>
----

<1> the maximum direct memory size for the implicit storage role is set to `2g` causing the `-XX:MaxDirectMemorySize=2g`
argument to be passed to the JVM.

==== Configuring the JVM Native Memory Size for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        memory:
          directMemorySize: 2g  # <1>
    - role: proxy
      jvm:
        memory:
          directMemorySize: 1g  # <2>
----

<1> the maximum direct memory size for the `data` role is set to `2g` causing the `-XX:MaxDirectMemorySize=2g`
argument to be passed to the JVM.
<2> the maximum direct memory size for the `proxy` role is set to `1g` causing the `-XX:MaxDirectMemorySize=1g`
argument to be passed to the JVM.


==== Configuring the JVM Native Memory Size for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      directMemorySize: 1g      # <1>
  roles:
    - role: data                # <2>
      jvm:
        memory:
          directMemorySize: 2g
    - role: proxy               # <3>
----


// ----- Native Memory Tracking ----------------------------------------------------------------------------------------

[#nmt]
=== Native Memory Tracking

The Native memory tracking mode can be configured for JVMs using the `jvm.memory.nativeMemoryTracking` field to track
JVM nio memory usage, which can be useful when  debugging nio memory issues. Setting the `nativeMemoryTracking` value
causes the `-XX:NativeMemoryTracking` JVM argument to be set.
If the `jvm.memory.nativeMemoryTracking` field is not specified a value of `summary` is used passing
`-XX:NativeMemoryTracking=summary` to the JVM.
See the https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr007.html[native memory tracking]
documentation.


==== Configuring Native Memory Tracking for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role native memory tracking can be configured in the `spec`
section of the yaml.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      nativeMemoryTracking: detail  # <1>
----

<1> The native memory tracking mode for the JVMs in the implicit storage role will be set to `detail` causing the
`-XX:NativeMemoryTracking=detail` to be passed to the JVMs.


==== Configuring Native Memory Tracking for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles native memory tracking can br configured specifically
for each role in the `roles` list.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        memory:
          nativeMemoryTracking: detail   # <1>
    - role: proxy
      jvm:
        memory:
          nativeMemoryTracking: summary  # <2>
----

<1> The native memory tracking mode for the JVMs in the `data` role will be set to `detail` causing the
`-XX:NativeMemoryTracking=detail` to be passed to the JVMs.
<2> The native memory tracking mode for the JVMs in the `proxy` role will be set to `summary` causing the
`-XX:NativeMemoryTracking=summary` to be passed to the JVMs.


==== Configuring Native Memory Tracking for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default native memory tracking mode can be set in
the `spec` section which will apply to all roles in the `roles` list unless specifically overridden for a role.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      nativeMemoryTracking: off         # <1>
  roles:
    - role: data                        # <2>
      jvm:
        memory:
          nativeMemoryTracking: detail
    - role: proxy                       # <3>
----

<1> The default native memory tracking mode is set to `off` for all roles in the `roles` list unless specifically
overridden. This will cause the `-XX:NativeMemoryTracking=off` to be passed to the JVMs.
<2> The native memory tracking mode is specifically set to `detail` for the `data` role causing the
`-XX:NativeMemoryTracking=detail` to be passed to the JVMs in the `data` role.
<3> The native memory tracking mode is not set for the `proxy` role so it will use the default value of `off` causing
the `-XX:NativeMemoryTracking=off` to be passed to the JVMs in the `proxy` role.


// ----- JVM OOM Behavior ----------------------------------------------------------------------------------------------

[#oom]
=== JVM Behaviour on Out Of Memory

It is an important recommendation in the Coherence documentation to specifically set the behaviour of a JVM when it
encounters an out of memory error. The JVM should be set to exit and generate a heap dump. A JVM that encounters an OOM
error is left in an undefined state and this can cause a Coherence cluster to become unstable if the JVM does not exit.
Generating a heap dump is useful to diagnose why the JVM had the OOM error.

There are two boolean fields in the `CoherenceCluster` CRD that control this behaviour:

* `jvm.memory.onOutOfMemory.exit` which determines whether the JVM will exit on an OOM error; the default value if
the field is not specified is `true`.
A value of `true` causes the `-XX:+ExitOnOutOfMemoryError` argument to be passed to the JVM.
* `jvm.memory.onOutOfMemory.heapDump` which determines whether the JVM will generate a heap dump on an OOM error; the
default value if the field is not specified is `true`.

Heap dumps will be written to a file `/jvm/${POD_NAME}/${POD_UID}/heap-dumps/${POD_NAME}-${POD_UID}.hprof`. The root
`/jvm` directory can be mapped to an external volume for easier access to the heap dumps
(see: <<#diagnosticsVolume,setting the disgnostic volume>>)


==== Configuring OOM Behaviour for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role native memory tracking can be configured in the `spec`
section of the yaml.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      onOutOfMemory:
        exit: true      # <1>
        heapDump: true  # <2>
----

<1> The implicit storage role will exit if an out of memory error occurs, the `-XX:+ExitOnOutOfMemoryError` argument
will be passed to the JVM
<2> The implicit storage role will generate a heap dump if an out of memory error occurs, the
`-XX:+HeapDumpOnOutOfMemoryError"` argument will be passed to the JVM


==== Configuring OOM Behaviour for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles native memory tracking can br configured specifically
for each role in the `roles` list.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        memory:
          onOutOfMemory:
            exit: true       # <1>
            heapDump: true   # <2>
    - role: proxy
      jvm:
        memory:
          onOutOfMemory:
            exit: false      # <3>
            heapDump: false  # <4>
----

<1> The `data` role will exit if an out of memory error occurs, the `-XX:+ExitOnOutOfMemoryError` argument
will be passed to the JVM
<2> The `data` role will generate a heap dump if an out of memory error occurs, the
`-XX:+HeapDumpOnOutOfMemoryError"` argument will be passed to the JVM
<3> The `proxy` role will not exit if an out of memory error occurs, the `-XX:+ExitOnOutOfMemoryError` argument
will be not passed to the JVM
<4> The `proxy` role will not generate a heap dump if an out of memory error occurs, the
`-XX:+HeapDumpOnOutOfMemoryError"` argument will not be passed to the JVM


==== Configuring OOM Behaviour for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default native memory tracking mode can be set in
the `spec` section which will apply to all roles in the `roles` list unless specifically overridden for a role.
For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    memory:
      onOutOfMemory:
        exit: false          # <1>
        heapDump: false      # <2>
  roles:
    - role: data
      jvm:
        memory:
          onOutOfMemory:
            exit: true       # <3>
            heapDump: true   # <4>
    - role: proxy            # <5>
----

<1> The default setting for exit on out of memory error is `false`
<2> The default setting for generating a heap dump on out of memory error is `false`
<3> The `data` role overrides the default `jvm.memory.onOutOfMemory.exit` value to `true` and will exit if an out of
memory error occurs, the `-XX:+ExitOnOutOfMemoryError` argument will be passed to the JVM
<4> The `data` role overrides the default `jvm.memory.onOutOfMemory.heapDump` value to `true` and will generate a heap
dump if an out of memory error occurs, `-XX:+HeapDumpOnOutOfMemoryError"` argument will be passed to the JVM
<5> The `proxy` role does not specify any values for `jvm.memory.onOutOfMemory.exit` or
`jvm.memory.onOutOfMemory.heapDump` so it will use the default values of `false`, the `-XX:+ExitOnOutOfMemoryError` and
`-XX:+HeapDumpOnOutOfMemoryError"` arguments will not be passed to the JVM


// ----- JMX Configuration ---------------------------------------------------------------------------------------------
'''
[#jmx]
== JMX Management Configuration

Using Java Management Extensions (JMX) can be unreliable in container based environments due to the limitations of the
default RMI transport used by JMX. A more reliable approach is to use an alternative transport and to this end the
Coherence Operator enables JMXMP to be configured and used to expose JMX functionality outside of the containers.

JMXMP is configured using the fields in the `jvm.jmxmp` section of the configuration.
Enabling JMXMP support adds the `opendmk_jmxremote_optional_jar.jar` JMXMP library to the classpath and sets the
configures the Coherence MBean server factory to produce a JMXMP MBean server. By default the JMXMP server will bind
to port 9099 in the container but this can be configured to bind to a different port.

NOTE: Using a custom transport for JMX, such as JMXMP, requires any JMX client that will connect to the JMX server to
also have a JMXMP library on its classpath.

See the <<management/040_visualvm.adoc,VisualVM Example>> for a detailed example of how to configure a JMX Management
role in a `CoherenceCluster`.


=== Configure JMXMP for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role the `useContainerLimits` is set in the `spec.jvm`
section of the configuration. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    jmxmp:
      enabled: true  # <1>
----

<1> JMXMP is enabled for the implicit storage role

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    jmxmp:
      enabled: true  # <1>
      port: 7000     # <2>
----

<1> JMXMP is enabled for the implicit storage role
<2> The JMXMP server will bind to port `7000` in the container instead of the default `9099`

=== Setting Container Resource Limits for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles the `jmxmp` can be configured in the `jvm`
section of the configuration for each `role` in the `roles` list. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        jmxmp:           # <1>
          enabled: true
          port: 7000
    - role: proxy
      jvm:
        jmxmp:           # <2>
          enabled: false
----

<1> The `data` role has JMXMP enabled and bound to port 7000
<2> The `proxy` role specifically has JMXMP disabled

=== Setting Container Resource Limits for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default `jmxmp` values can be configured in
the `CoherenceCluster` `spec` section that will apply to all of the roles in the `roles` list unless explicitly
overridden for a role. For example:


[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    jmxmp:                 # <1>
      enabled: true
  roles:
    - role: data
      jvm:
        jmxmp:             # <2>
          port: 7000
    - role: proxy
      jvm:
        jmxmp:             # <3>
          enabled: false
    - role: web            # <4>
----

<1> The default settings enable JMXMP support for all roles in the `roles` list unless overridden
<2> The `data` role will have JMXMP enabled due to the default setting and also adds the `port` configuration to bind
JMXMP to port `7000`
<3> The `proxy` role explicity overrides the default to disable JMXMP
<4> The `web` role has no specific `jmxmp` configuration so will use the default that will enable JMXMP and bind the
server to port `9099`



// ----- Use Container Limits ------------------------------------------------------------------------------------------
'''
[#useContainerLimits]
== Container Resource Limits

When running JVMs inside containers it is recommended to configure the JVM to respect the memory and CPU resource limits
that are configured for the container. This is especially important in Kubernetes where the `Pod` may be terminated if a
container exceeds the configured resource limits. The `jvm.useContainerLimits` field is used to either add or omit the
`-XX:+UseContainerSupport` JVM argument. If `useContainerLimits` is set to `true` then `-XX:+UseContainerSupport` is
added to the JVM arguments, if `useContainerLimits` is set to `false` then `-XX:+UseContainerSupport` is not
added to the JVM arguments.

The default value of `useContainerLimits` if not specified is `true` so `-XX:+UseContainerSupport` will always be added
to the JVM arguments unless `useContainerLimits` is explicitly set to `false`. It is recommended that this value be left
unspecified as the default `true` unless other arguments are being passed to the JVM to limit its resource usage.

=== Setting Container Resource Limits for the Implicit Role

When creating a `CoherenceCluster` with a single implicit role the `useContainerLimits` is set in the `spec.jvm`
section of the configuration. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    useContainerLimits: true  # <1>
----

<1> The `-XX:+UseContainerSupport` JVM option will be passed as arguments to the JVM for the implicit storage role.


=== Setting Container Resource Limits for Explicit Roles

When creating a `CoherenceCluster` with one or more explicit roles the `useContainerLimits` are set in the `jvm`
section of the configuration for each `role` in the `roles` list. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  roles:
    - role: data
      jvm:
        useContainerLimits: true  # <1>
    - role: proxy
      jvm:
        useContainerLimits: false  # <2>
----

<1> The `-XX:+UseContainerSupport` JVM option will be passed as arguments to the JVM for the explicit `data` role.
<2> The `-XX:+UseContainerSupport` JVM option will not be passed as arguments to the JVM for the explicit `proxy` role.


=== Setting Container Resource Limits for Explicit Roles with a Default

When creating a `CoherenceCluster` with one or more explicit roles a default `useContainerLimits` value can be set in
the `CoherenceCluster` `spec` section that will apply to all of the roles in the `roles` list unless explicitly
overridden for a role. For example:

[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: CoherenceCluster
metadata:
  name: test-cluster
spec:
  jvm:
    useContainerLimits: true        # <1>
  roles:
    - role: data                    # <2>
      jvm:
        useContainerLimits: false
    - role: proxy                   # <3>
----

<1> The default `useContainerLimits` is set to `true`.
<2> The `data` role overrides the default `useContainerLimits` and sets it to `false`.
<3> The `proxy` role does not specify any `useContainerLimits` value so will use the default of `true`.


// ----- Flight Recorder -----------------------------------------------------------------------------------------------
'''
[#flightRecorder]
== Flight Recorder

Flight Recorder is a useful tool to use when diagnosing issues with a Coherence application or as an aid to performance
and GC tuning. By default the JVMs in a `CoherenceCluster` are configured to produce a continual flight recording that
will be dumped to a file when the JVM exits.

The `/jvm` root directory used for `.jfr` files can be <<#diagnosticsVolume,mounted to an external volume>> to allow
easier access to these files.


// ----- Diagnostic Volume ---------------------------------------------------------------------------------------------
'''
[#diagnosticsVolume]
== Diagnostic Volume

By default the Coherence JVMs are configured to write heap dumps, error logs and flight recordings to directories in the
container under the root `/jvm` directory. The `/jvm` directory is mapped to `volumeMount` named `jvm` which is in turn
mapped to a `volume` named `jvm`.

The default configuration for the `jvm` volume in the Coherence `Pods` is an empty directory.
[source,yaml]
----
volumeMounts:
  - name: jvm
    mountPath: /jvm
volumes:
  - name: jvm
    emptyDir: {}
----

The default may be changed to map the `jvm` volume to any supported
https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes[Kubernetes `VolumeSource`].


// ----- JVM Debug Arguments -------------------------------------------------------------------------------------------

[#debug]
== JVM Debug Arguments

Sometimes attaching a debugger to a JVM is the best way to track down the cause of an issue. The `CoherenceCluster` CRD
has a number of fields that can be used to configure how the JVM can be started in debug mode.


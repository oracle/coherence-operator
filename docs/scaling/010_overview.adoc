///////////////////////////////////////////////////////////////////////////////

    Copyright (c) 2020, 2025, Oracle and/or its affiliates.
    Licensed under the Universal Permissive License v 1.0 as shown at
    http://oss.oracle.com/licenses/upl.

///////////////////////////////////////////////////////////////////////////////

= Scale Coherence Deployments
:description: Coherence Operator Documentation - Scale Coherence Deployments
:keywords: oracle coherence, kubernetes, operator, scale coehrence, scale deployments

== Scale Coherence Deployments

The Coherence Operator provides the ability to safely scale up and down a `Coherence` deployment.
A `Coherence` deployment is backed by a `StatefulSet`, which can easily be scaled using existing Kubernetes features.
The problem with directly scaling down the `StatefulSet` is that Kubernetes will immediately kill the required number
of `Pods`. This is obviously very bad for Coherence as killing multiple storage enabled members would almost certainly
cause data loss.

The Coherence Operator supports scaling by applying the scaling update directly to `Coherence` deployment rather than
to the underlying `StatefulSet`. There are two methods to scale a `Coherence` deployment:

* Update the `replicas` field in the `Coherence` CRD spec.
* Use the `kubectl scale` command 

When either of these methods is used the Operator will detect that a change to the size of the deployment is required
and ensure that the change will be applied safely. The logical steps the Operator will perform are:

1. Detect desired replicas is different to current replicas
2. Check the cluster is StatusHA - i.e. no cache services are endangered. If any service is not StatusHA requeue the
scale request  (go back to step one).
3. If scaling up, add the required number of members.
4. If scaling down, scale down by one member and requeue the request (go back to step one).

What these steps ensure is that the deployment will not be resized unless the cluster is in a safe state.
When scaling down only a single member will be removed at a time, ensuring that the cluster is in a safe state before
removing the next member.

NOTE: The Operator will only apply safe scaling functionality to deployments that are storage enabled.
If a deployment is storage disabled then it can be scaled up or down by the required number of members
in one step as there is no fear of data loss in a storage disabled member.

[#problem]
== Kubectl Scale & Autoscaling

When using the `kubectl scale` command or the Kubernetes autoscaler to scale Coherence clusters it is important
to be aware of how replicas are controlled when later applying updates to a cluster.

=== The Problem

If the replica count that has been changed via one of the scaling commands, when later updating it using an edited
version of the original YAML the replicas may be reverted and the cluster inadvertently resized.

For example, a Coherence cluster can be defined with the `storage-cluster.yaml` file shown below.

[source,yaml]
.storage-cluster.yaml
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: storage
spec:
  replicas: 6
----

Applying the YAML file will create a cluster with six Pods.
[source,bash]
----
kubectl apply -f storage-cluster.yaml
----

The cluster can then be scaled using kubectl scale
[source,bash]
----
kubectl scale coh/storage --replicas=9
----

The cluster now has nine Pods. Later an update is applied to add a new system property to the JVM by
editing the original YAML file:

[source,yaml]
.storage-cluster.yaml
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: storage
spec:
  replicas: 6
  jvm:
    args:
      - "-Dfoo=bar"
----

The update can be applied using kubectl apply:
[source,bash]
----
kubectl apply -f storage-cluster.yaml
----

But, the YAML file contains the original replica count, so the cluster will be scaled back from nine to six Pods.
This is probably not what was desired.

One solution is to always make sure the replicas in the yaml is set to the "correct" value before applying it.
This can be awkward in some environments, and especially if using the Kubernetes HPA to control scaling.

=== The Solutions

If you intend to use `kubectl scale` or the Kubernetes HPA to control scaling there are two options to fix the
issue described above.

1: <<replicas_not_set,Do not set the replicas field.>>

2: <<initial_replicas_set,Set the initial cluster size using the `initialReplicas` field.>>

[#replicas_not_set]
==== 1: Do Not Set Replicas

If you intend to use `kubectl scale` or the Kubernetes HPA to control scaling then you can choose not to set the
`replicas` field in the YAML file used to create and update the Coherence cluster.
The operator will then create a cluster with the default three replicas.

For example, the initial YAML above could have been created like this:

[source,yaml]
.storage-cluster.yaml
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: storage
----

After applying the YAML, the cluster size would start with the default three Pods.
After creation, the cluster can easily be scaled up to its required size using `kubectl scale`

Later when applying the system property update, again the `replicas` field is unset in the YAML file:
[source,yaml]
.storage-cluster.yaml
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: storage
spec:
  jvm:
    args:
      - "-Dfoo=bar"
----

Now, when the above YAML is applied using `kubectl apply` the replicas value for the cluster will be unchanged and
stay at whatever value it was scaled to.

Another solution would be to create the initial YAML with the `replicas` field set to the desired initial size.
Then later when applying updates, ensure that the `replicas` field has been deleted from the YAML file.

[#initial_replicas_set]
==== 2: Use the `initialReplicas` Field

The `Coherence` resource spec contains an `initialReplicas` field which can be used to specify the initial size of the
cluster. This field can be used when a cluster needs an initial size greater or smaller than the operator's default
size of three replicas.

For example, the yaml below will create a StatefulSet with a replica count of six.
[source,yaml]
.storage-cluster.yaml
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: storage
spec:
  initialReplicas: 6
----

[NOTE]
====
If both the `initialReplicas` field and the `replicas` field are set then the `replicas` field willl be used to set the cluster size.
====

When the Coherence cluster is scaled using either the HPA or the `kubectl scale` command then they will set the `replicas`
field in the Coherence spec which will scale up or down the cluster.
When an upgrade is performed by editing the original yaml that contains no `replicas` field and only the `initialReplicas`
field the resulting patch applied will not change whatever the current `replicas` value is that was set by the HPA or scale command.

== Controlling Safe Scaling

The `Coherence` CRD has a number of fields that control the behavior of scaling.

=== Scaling Policy

The `Coherence` CRD spec has a field `scaling.policy` that can be used to override the default scaling
behaviour. The scaling policy has three possible values:

[cols=2*,options=header]
|===
|Value
|Description

|`ParallelUpSafeDown`
|This is the default scaling policy.
With this policy when scaling up `Pods` are added in parallel (the same as using the `Parallel` `podManagementPolicy`
in a https://{k8s-doc-link}/#statefulsetspec-v1-apps[StatefulSet]) and
when scaling down `Pods` are removed one at a time (the same as the `OrderedReady` `podManagementPolicy` for a
StatefulSet). When scaling down a check is done to ensure that the members of the cluster have a safe StatusHA value
before a `Pod` is removed (i.e. none of the Coherence cache services have an endangered status).
This policy offers faster scaling up and start-up because pods are added in parallel as data should not be lost when
adding members, but offers safe, albeit slower,  scaling down as `Pods` are removed one by one.

|`Parallel`
|With this policy when scaling up `Pods` are added in parallel (the same as using the `Parallel` `podManagementPolicy`
in a https://{k8s-doc-link}/#statefulsetspec-v1-apps[StatefulSet]).
With this policy no StatusHA check is performed either when scaling up or when scaling down.
This policy allows faster start and scaling times but at the cost of no data safety; it is ideal for deployments that are
storage disabled.

|`Safe`
|With this policy when scaling up and down `Pods` are removed one at a time (the same as the `OrderedReady`
`podManagementPolicy` for a StatefulSet). When scaling down a check is done to ensure that the members of the deployment
have a safe StatusHA value before a `Pod` is removed (i.e. none of the Coherence cache services have an endangered status).
This policy is slower to start, scale up and scale down.
|===

Both the `ParallelUpSafeDown` and `Safe` policies will ensure no data loss when scaling a deployment.

The policy can be set as shown below:
[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: test
spec:
  scaling:
    policy: Safe # <1>
----
<1> This deployment will scale both up and down with StatusHA checks.

=== Scaling StatusHA Probe

The StatusHA check performed by the Operator uses a http endpoint that the Operator runs on a well-known port in the
Coherence JVM. This endpoint performs a simple check to verify that none of the partitioned cache services known
about by Coherence have an endangered status. If an application has a different concept of what "safe" means it can
implement a different method to check the status during scaling.

The operator supports different types of safety check probes, these are exactly the same as those supported by
Kubernetes for readiness and liveness probes. The `scaling.probe` section of the `Coherence` CRD allows different
types of probe to be configured.

==== Using a HTTP Get Probe

An HTTP get probe works the same way as a
https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-http-request[Kubernetes liveness http request]

The probe can be configured as follows
[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: test
spec:
  scaling:
    probe:
      httpGet:             # <1>
        port: 8080
        path: /statusha
----
<1> This deployment will check the status of the services by performing a http GET on `http://<pod-ip>:8080/statusha`.
If the response is `200` the check will pass, any other response the check is assumed to be false.

==== Using a TCP Probe

A TCP probe works the same way as a
https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-tcp-liveness-probe[Kubernetes TCP liveness probe]

The probe can be configured as follows
[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: test
spec:
  scaling:
    probe:
      tcpSocket:    # <1>
        port: 7000
----
<1> This deployment will check the status of the services by connecting to the socket on port `7000`.

==== Using an Exec Command Probe

An exec probe works the same way as a
https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command[Kubernetes Exec liveness probe]

The probe can be configured as follows
[source,yaml]
----
apiVersion: coherence.oracle.com/v1
kind: Coherence
metadata:
  name: test
spec:
  scaling:
    probe:
      exec:
        command:      # <1>
          - /bin/ah
          - safe.sh
----
<1> This deployment will check the status of the services by running the `sh safe.sh` command in the `Pod`.

